<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenda Xu</title>
  
  <meta name="author" content="Wenda Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wenda Xu</name>
              </p>
              <p>I am a PhD graduated from<a href="http://nlp.cs.ucsb.edu">UC Santa Barbara</a>. My advisors are <a href="https://sites.cs.ucsb.edu/~william/">Prof. William Wang</a> and <a href="http://www.cs.cmu.edu/~leili/">Prof. Lei Li</a>. I was a visiting scholar at CMU Language Technologies Institute (Email: <a href="wendaxu@ucsb.edu">wendaxu@ucsb.edu</a>).
              </p>
              <heading>Research Interests</heading>
              <p>
                My major research interests lie in the area of <strong>large language model (LLM) evaluation and efficient post-training</strong>. 
                I am the first author of SEScore1&2 and InstructScore (<strong>Best Unsupervised Text Generation metrics at WMT22 shared task</strong>). Currently, I am actively working on LLM post-training techniques, in both preference learning and knowledge distillation.
              </p>
              <p style="text-align:center">
                <a href="data/wendaxu_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wenda-xu-866040163/">Linkedin</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.il/citations?user=hUh7qCcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/WendaXu2">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/xu1998hz/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/wenda_new.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/wenda_new.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <h2><font color="red">Incoming Google Research Scientist!</font></h2>
            </td>
          </tr></tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <h1>Industry Experience</h1>
              <h2><em>Google Cloud AI Research</em></h2>
              <strong>Duration: </strong>06/2024 - 10/2024
              <br>
              <strong>Mentors: </strong>Chen-Yu Lee, Rishabh Agarwal
              <br>
              <strong>Hosts: </strong>Rujun Han, Zifeng Wang
              <br>
              <strong>Publication: </strong><a href="https://arxiv.org/abs/2410.11325">
                <papertitle>Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling</papertitle>
              </a>

              <h2><em>Google Translate Research</em></h2>
              <strong>Duration: </strong>06/2023 - 12/2023
              <br>
              <strong>Mentors: </strong>Markus Freitag
              <br>
              <strong>Hosts: </strong>Dan Deutsch, Mara Finkelstein, Juraj Juraska
              <br>
              <strong>Publication: </strong><a href="https://arxiv.org/abs/2311.09336">
                <papertitle>LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback</papertitle>
              </a>

              <h2><em>ByteDance AI Lab</em></h2>
              <strong>Duration: </strong>06/2022 - 10/2022
              <br>
              <strong>Mentors: </strong>Mingxuan Wang
              <br>
              <strong>Hosts: </strong>Xian Qian
              <br>
              <strong>Publication: </strong><a href="https://arxiv.org/abs/2212.09305">
                <papertitle>SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes</papertitle>
              </a>
            </td>
          </tr></tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h1>Efficient Post-training</h1>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Aligning student LLM to teacher LLM (Post-training stage)</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
          
            <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/regnerf_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/skd.png' width="180" height="140">
                </div>
                <script type="text/javascript">
                  function regnerf_start() {
                    document.getElementById('regnerf_image').style.opacity = "1";
                  }
  
                  function regnerf_stop() {
                    document.getElementById('regnerf_image').style.opacity = "0";
                  }
                  regnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2410.11325">
                  <papertitle>Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling</papertitle>
                </a>
                <br>
                <strong>Wenda Xu</strong>, Rujun Han, Zifeng Wang, Long Le, Dhruv Madeka, Lei Li, William Yang Wang, Rishabh Agarwal, Chen-Yu Lee, Tomas Pfister
                <br>
                ICLR 2025
                <br> 
                <a href="https://arxiv.org/abs/2410.11325">project page</a>
          /
                <a href="https://arxiv.org/abs/2410.11325">arXiv</a>
          /
                <a href="https://arxiv.org/abs/2410.11325">code</a>
                <p></p>
                <p>We use Interleaved sampling that utilizes on-policy student samples likely to be generated by the teacher, mitigating the issues of low-quality samples in on-policy KD and dynamically switching
                  between supervised and on-policy KD. Our experiments consistently show SKD's superiority in both task-specific and task-agnostic distillations. SKD is robust to various model families, initialization, and dataset sizes. 
                </p>
              </td>
            </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Aligning LLM with AI or human feedback (Post-training stage)</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/BPO.png' width="180" height="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2406.12168">
                <papertitle>BPO: Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM </papertitle>
              </a>
              <br>
              <strong>Wenda Xu*</strong>, Jiachen Li*, William Yang Wang, Lei Li
              <br>
              *Two authors contributed equally
              <br>
              EMNLP Main 2024
              <br> 
              <a href="https://arxiv.org/abs/2406.12168">project page</a>
        /
              <a href="https://arxiv.org/abs/2406.12168">arXiv</a>
        /
              <a href="https://arxiv.org/abs/2406.12168">code</a>
              <p></p>
              <p>Online BPO: our 1) We collect data in the on-policy/online fashion 2) we respect behavior LLM when constructing trust region. 3) With only two phrase of online data collection, we can significantly improve offline DPO (<strong>TL;DR (72.0%->89.5%), Helpfulness (82.2%->93.5%), Harmfulness (77.5%->97.7%)</strong>).
              </p>
            </td>
          </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Data augmentation to align LLM (Pre-training stage)</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/expert_layman.png' width="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.02950">
                <papertitle>Self-Supervised Knowledge Assimilation for Expert-Layman Text Style Transfer</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Michael Saxon, Misha Sra, William Yang Wang
              <br>
              AAAI2022
              <br>
              <a href="https://github.com/xu1998hz/SSL_KBA_Expert_Layman_Style_Transfer">project page</a>
        /
              <a href="https://arxiv.org/abs/2110.02950">arXiv</a>
        /
              <a href="https://github.com/xu1998hz/SSL_KBA_Expert_Layman_Style_Transfer">code</a>
        
              <br>
              <!-- <strong>Thanks to my girlfriend Jeselle-Ann Laxa for initiating this project!</strong> -->
              <p> We develop a self-supervised approach to perform expert layman text style transfer. We propose a novel
                SSL task knowledge base assimilation to inject knowledge into pretraining. We achieve amazing performance 
                in human evaluation, <strong>relative improving overall success rate by 106%!</strong>
              </p>
            </td>
          </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Using fine-grained LLM agent to align large language model (Inference stage)</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/SA_LLM.png' width="180" height="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.09336">
                <papertitle>LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Daniel Deutsch, Mara Finkelstein, Juraj Juraska, Biao Zhang, Zhongtao Liu, William Yang Wang, Lei Li, Markus Freitag
              <br>
              NAACL 2024
              <br> 
              <a href="https://arxiv.org/pdf/2311.09336.pdf">project page</a>
        /
              <a href="https://arxiv.org/abs/2311.09336">arXiv</a>
        /
              <a href="https://arxiv.org/pdf/2311.09336.pdf">code</a>
              <p></p>
              <p>Can we not criticize LLM but pinpoint errors it makes and automatically guide it with fine-grained actionable feedback? Can we formulate iterative refinement into a local search problem, simulated annealing? This is the work after my prior work InstructScore, where I really think about how to incorporate fine-grained actionable feedback to guide text generation. <strong>Fine-grained LLM agent iteratively improves PALM2 for 1.7 MetricX points on translation tasks, 8.1 ROUGE-L on ASQA, 2.2 ROUGE-L on topical summarization</strong>.
              </p>
            </td>
          </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h1>Large Language Model Evaluation</h1>
            </td>
          </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Pitfalls of LLM‚Äôs self-quality assessment</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/peril_self_refine.png' width="180" height="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.11436">
                <papertitle>Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, William Yang Wang
              <br>
              ACL 2024 Main (<font color="red"><strong>Oral</strong></font>)
              <br> 
              <a href="https://arxiv.org/pdf/2402.11436.pdf">project page</a>
        /
              <a href="https://arxiv.org/pdf/2402.11436.pdf">arXiv</a>
        /
              <a href="https://arxiv.org/pdf/2402.11436.pdf">code</a>
              <p></p>
              <p>Self-feedback display model's bias towards their own outputs. We find that self-bias is prevalent in all examined LLMs across multiple languages and tasks (6 LLMs, 4 languages, 3 tasks). To mitigate such biases, we discover that larger mode size and external feedback with accurate assessment can significantly reduce bias in the self-refine pipeline, leading to actual performance improvement in downstream tasks. <strong>First define and quantify
                LLM‚Äôs self-bias towards its own outputs.</strong>
              </p>
            </td>
          </tr> 

          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Learning explainable and fine-grained quality feedback</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/instructscore.png' width="190" height="160">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2305.14282">
                <papertitle>INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained Feedback</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag, William Yang Wang, Lei Li
              <br>
              EMNLP Main 2023 (<font color="red"><strong>Oral</strong></font>)
              <br> 
              <a href="https://github.com/xu1998hz/SEScore3">project page</a>
        /
              <a href="https://arxiv.org/abs/2305.14282">arXiv</a>
        /
              <a href="https://github.com/xu1998hz/SEScore3">code</a>
              <p></p>
              <p>InstructScore is an explainable text generation metric, which instead of outputing a scalar score, it outputs error location, error type and severity measures to candidate text. <strong>Fine-grained 7B LLM evaluator surpasses all other unsupervised metrics,
                including those based on 175B GPT-3 and GPT-4.</strong>
              </p>
            </td>
          </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><em>Learning to evaluate the quality of generated text without labels</em></heading>
            </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/sescore2_teaser.png' width="190" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2212.09305">
                <papertitle>SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Xian Qian, Mingxuan Wang, Lei Li, William Yang Wang
              <br>
              ACL Main 2023
              <br> 
              <a href="https://github.com/xu1998hz/SEScore2">project page</a>
        /
              <a href="https://arxiv.org/abs/2212.09305">arXiv</a>
        /
              <a href="https://github.com/xu1998hz/SEScore2">code</a>
              <p></p>
              <p>SESCORE2, is a SSL method to train a metric for general text generation tasks without human ratings. We develop a technique to synthesize candidate sentences with varying levels of mistakes for training. To make these self-constructed samples realistic, we introduce retrieval augmented synthesis on anchor text; 
                It outperforms SEScore in four text generation tasks with three languages (<strong>The overall kendall correlation improves 14.3%</strong>). 
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/SEScore.png' width="180" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.05035">
                <papertitle>Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis</papertitle>
              </a>
              <br>
              <strong>Wenda Xu</strong>, Yi-lin Tuan, Yujie Lu, Michael Saxon, Lei Li, William Yang Wang
              <br>
        EMNLP2022 and also appeared at <em>WMT22 shared metric task</em> <font color="red"><strong>(Best unsupervised metric)</strong></font>
              <br>
              <a href="https://github.com/xu1998hz/SEScore">project page</a>
        /
              <a href="https://arxiv.org/abs/2210.05035">arXiv</a>
        /
              <a href="https://github.com/xu1998hz/SEScore">code</a>
        /
              <a href="https://huggingface.co/spaces/xu1998hz/sescore">HuggingFace</a>
              <p></p>
              <p><strong>SEScore</strong> is a reference-based text-generation evaluation metric that requires no pre-human-annotated data to train on. We develop a novel stratified error synthesis to synthesize diverse errors with varying severity levels at raw data. Then, we learn a neural metric to automatically give ratings to model generated texts. <strong>Its effectiveness over prior methods like BLEU, BERTScore, COMET and BLEURT has been demonstrated on various NLG tasks.</strong> 
              </p>
            </td>
          </tr> 


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h1>Selected Collaboration Publications</h1>
            </td>
            </tr>
          </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/fig3.png' width="190" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2410.16011">
                <papertitle>CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation</papertitle>
              </a>
              <br>
              Xi Xu, <strong>Wenda Xu</strong>, Siqi Ouyang, Lei Li
              <br>
              NAACL 2025
              <br>
              <a href="https://arxiv.org/abs/2410.16011">arXiv</a>
        /
              <a href="https://arxiv.org/abs/2410.16011">code</a>
              
              
              <p> There has been a longstanding belief that current metrics yield unrealistically high latency measurements in unsegmented streaming settings. In this paper, we investigate this phenomenon, revealing its root cause in a fundamental misconception underlying existing latency evaluation approaches.
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/profile.png' width="190" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2410.06965">
                <papertitle>Uncovering Factor Level Preferences to Improve Human-Model Alignment</papertitle>
              </a>
              <br>
              Juhyun Oh, Eunsu Kim, Jiseon Kim, <strong>Wenda Xu</strong>, Inha Cha, William Yang Wang, Alice Oh
              <br>
              Preprint
              <br>
              <a href="https://arxiv.org/pdf/2410.06965">arXiv</a>
        /
              <a href="https://arxiv.org/pdf/2410.06965">code</a>
              
              
              <p> We introduce PROFILE (PRObing Factors of InfLuence for Explainability), a novel framework that uncovers and quantifies the influence of specific factors driving preferences. 
                PROFILE's factor level analysis explains the ``why'' behind human-model alignment and misalignment, offering insights into the direction of model improvement.
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/submit-workflow.png' width="190" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2410.10861">
                <papertitle>Translation Canvas: An Explainable Interface to Pinpoint and Analyze Translation Systems</papertitle>
              </a>
              <br>
              Chinmay Dandekar, <strong>Wenda Xu</strong>, Xi Xu, Siqi Ouyang, Lei Li
              <br>
              EMNLP 2024 Demo
              <br>
              <a href="https://arxiv.org/abs/2410.10861">arXiv</a>
        /
              <a href="https://pypi.org/project/translation-canvas/">code</a>
              
              <p> We build an interactive transaltion canvas to visualize InstructScore, highlighting
                error spans with explanations and selectively displaying systems' predictions. Translation Canvas assists machine trans
                lation researchers in comprehending system-level model performance by identifying common errors (their frequency and severity). 
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/self-correct.png' width="190" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://aclanthology.org/2024.tacl-1.27/">
                <papertitle>Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies</papertitle>
              </a>
              <br>
              Liangming Pan, Michael Saxon, <strong>Wenda Xu</strong>, Deepak Nathani, Xinyi Wang, William Yang Wang
              <br>
              TACL 2024
              <br>
              <a href="https://arxiv.org/pdf/2308.03188.pdf">arXiv</a>
        /
              <a href="https://github.com/teacherpeterpan/self-correction-llm-papers">code</a>
              
              <p> A survey of self-correct strategies of LLM, including training-time, generation-time and inference-time approaches.
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/dialogue.png' width="180" height="120">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2212.10515.pdf">
                <papertitle>CausalDialogue: Modeling Utterance-level Causality in Conversations</papertitle>
              </a>
              <br>
              Yi-Lin Tuan, Alon Albalak, <strong>Wenda Xu</strong>, Michael Saxon, Connor Pryor, Lise Getoor, William Yang Wang
              <br>
              ACL 2023
              <br>
              <a href="https://arxiv.org/pdf/2212.10515.pdf">arXiv</a>
        /
              <a href="https://github.com/Pascalson/CausalDialogue">code</a>
        
              <!-- <p></p> -->
              
              <p> New work explores the causal relationship encoded in branching dialogue graphs from RPG video game. 
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/peco.png' width="180">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.09237">
                <papertitle>PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers</papertitle>
              </a>
              <br>
              Michael Saxon, Xinyi Wang, <strong>Wenda Xu</strong>, William Yang Wang
              <br>
              EACL 2023
              <br>
              <a href="https://arxiv.org/abs/2112.09237">arXiv</a>
        /
              <a href="https://github.com/michaelsaxon/DatasetAnalysis">code</a>
        
              <!-- <p></p> -->
              
              <p> We demonstrated automated detection of spurious, annotator-driven correlations that lead to cheating features in NLI. 
              </p>
            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/causal.png' width="180" height="100">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2206.02928">
                <papertitle>Neuro-Symbolic Procedural Planning with Commonsense Prompting</papertitle>
              </a>
              <br>
              Yujie Lu, Weixi Feng, Wanrong Zhu, <strong>Wenda Xu</strong>, Xin Eric Wang, Miguel Eckstein, William Yang Wang
              <br>
              ICLR 2023
              <br>
              <a href="https://arxiv.org/abs/2206.02928">arXiv</a>
        /
              <a href="">code</a>
              
              <p>This work mitigates spurious correlations by using symbolic program executors on latent procedural representations</p>
              <br>
              <br>
              <p> 
              </p>
            </td>
          </tr>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/imagine.png' width="180" height="100">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.03765">
                <papertitle>Visualize Before You Write: Imagination-Guided Open-Ended Text Generation</papertitle>
              </a>
              <br>
              Wanrong Zhu, An Yan, Yujie Lu, <strong>Wenda Xu</strong>, Xin Eric Wang, Miguel Eckstein, William Yang Wang
              <br>
              EACL 2023
              <br>
              <a href="https://arxiv.org/abs/2210.03765">arXiv</a>
        /
              <a href="https://github.com/VegB/iNLG">code</a>
        
              <p>Introduce a novel paradigm that leverages machine-generated images to guide open-ended text generation. This endows the machines with the ability of creative visualization that human writers often demonstrate.</p>
              <br>
              <br>
              <br>
              <br>
              <p> 
              </p>
            </td>
          </tr>

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='regnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/regnerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/kongzi.png' width="160" height="240">
              </div>
              <script type="text/javascript">
                function regnerf_start() {
                  document.getElementById('regnerf_image').style.opacity = "1";
                }

                function regnerf_stop() {
                  document.getElementById('regnerf_image').style.opacity = "0";
                }
                regnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle></papertitle>
              </a>
              <h2>Fun Fact: What is the meaning of Wenda(ÈóªËææ)?</h2>
              <h3>I add this because Starbucks people keep putting down "Wendy" or "Wanda"</h3>
              Â≠êÂº†ÈóÆÔºö‚ÄúÂ£´‰ΩïÂ¶ÇÊñØÂèØË∞ì‰πãËææÁü£Ôºü‚Äù
              <br>
              Â≠êÊõ∞Ôºö‚Äú‰ΩïÂìâÔºåÂ∞îÊâÄË∞ìËææËÄÖÔºü‚Äù
              <br>
              Â≠êÂº†ÂØπÊõ∞Ôºö‚ÄúÂú®ÈÇ¶ÂøÖÈóªÔºåÂú®ÂÆ∂ÂøÖÈóª„ÄÇ‚Äù
              <br>
              Â≠êÊõ∞Ôºö‚ÄúÊòØÈóª‰πüÔºåÈùûËææ‰πü„ÄÇÂ§´Ëææ‰πüËÄÖÔºåË¥®Áõ¥ËÄåÂ•Ω‰πâÔºåÂØüË®ÄËÄåËßÇËâ≤ÔºåËôë‰ª•‰∏ã‰∫∫„ÄÇÂú®ÈÇ¶ÂøÖËææÔºåÂú®ÂÆ∂ÂøÖËææ„ÄÇÂ§´Èóª‰πüËÄÖÔºåËâ≤Âèñ‰ªÅËÄåË°åËøùÔºåÂ±Ö‰πã‰∏çÁñë„ÄÇÂú®ÈÇ¶ÂøÖÈóªÔºåÂú®ÂÆ∂ÂøÖÈóª„ÄÇ‚Äù
              <br>
              <br>
              The origin of word <strong>"Wenda(ÈóªËææ)"</strong> was from a conversation between Confucius and his student. Here is the English translation:
              <br>
              <br>
              <strong>Zi Zhang asked</strong>, "What makes a scholar truly accomplished ('Da' means 'accomplished', Ëææ)?" 
              <br>
              <strong>Confucius asked</strong>, "Define 'accomplished'?" 
              <br>
              <strong>Zi Zhang replied</strong>, "To be renowned in the states of feudal lords, and to be renowned in the lands of ministers." 
              <br>
              <strong>Confucius said</strong>, "This is more about fame ('Wen' means 'fame', Èóª) than accomplishment. True accomplishment is about honesty, love for righteousness, understanding others, and modesty. Such a person will succeed anywhere. Those who seek fame may pretend to be virtuous, but their actions betray them, leading to hollow fame regardless of where they are."              <p></p>
              <br>
              <br>
              <br>
              <br>
              <p> 
              </p>
            </td>
          </tr>
      </td>
    </tr>
  </table>
</body>

</html>
